{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch_gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "87ea0c2bfc8d33363b62de134cfa12cc037bed7b7625ab24887ee8fe91891aef"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Photos found: 24996\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "dataset_version = \"lite\"\n",
    "photos_path = Path(\"../ML_data/unsplash-dataset\") / dataset_version/ \"photos\"\n",
    "photos_files = list(photos_path.glob(\"*.jpg\"))\n",
    "print(f\"Photos found: {len(photos_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device:cuda\n",
      "100%|████████████████████████████████████████| 354M/354M [16:08<00:00, 366kiB/s]\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Using device:{device}')\n",
    "model, prepocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clip_features(photos_batch):\n",
    "    photos = [Image.open(photo_file) for photo_file in photos_batch]\n",
    "    photos_preprocessed = torch.stack([prepocess(photo) for photo in photos]).to(device)\n",
    "    with torch.no_grad():\n",
    "        photos_features = model.encode_image(photos_preprocessed)\n",
    "        photos_features /= photos_features.norm(dim=-1, keepdim=True)\n",
    "    return photos_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]Total batches number:1563\n",
      "100%|██████████| 1563/1563 [14:11<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "batch_size = 16\n",
    "features_path = Path(\"../ML_data/unsplash-dataset\") / dataset_version/ \"features\"\n",
    "batches = math.ceil(len(photos_files) / batch_size)\n",
    "print(f\"Total batches number:{batches}\")\n",
    "for i in tqdm(range(batches)):\n",
    "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
    "    batch_features_path  = features_path / f\"{i:010d}.npy\"\n",
    "\n",
    "    if not batch_features_path.exists():\n",
    "        try:\n",
    "            # print(i, [photo_file for photo_file in batch_files])\n",
    "            batch_files = photos_files[i*batch_size: min(len(photos_files), (i+1)*batch_size)]\n",
    "            batch_features = compute_clip_features(batch_files)\n",
    "            np.save(batch_features_path, batch_features)\n",
    "            photo_ids = [photo_file.name.split(\".\")[0] for photo_file in batch_files]\n",
    "            photo_ids_data = pd.DataFrame(photo_ids, columns=['photo_id'])\n",
    "            photo_ids_data.to_csv(batch_ids_path, index=False)\n",
    "        except:\n",
    "            pass\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [np.load(feature_file) for feature_file in sorted(features_path.glob('*.npy'))]\n",
    "features = np.concatenate(features_list)\n",
    "np.save(features_path/\"features.npy\", features)\n",
    "photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob('*.csv'))])\n",
    "photo_ids.to_csv(features_path / \"photo_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(24756, 24756)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "len(features), len(photo_ids)"
   ]
  }
 ]
}